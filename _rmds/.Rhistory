library(MASS)
mtcars
data_set <- data.frame(rnorm(100), rnorm(100))
set.seed(100)
data_set <- data.frame(rnorm(100), rnorm(100))
colnames(data_set) <- c("y","x")
lm(y~x, data = data_set)
results <- lm(y~x, data = data_set)
summary(results)$coeff
x <- vector()
for (i in 1:100){
data_set <- data.frame(rnorm(1000), rnorm(1000))
colnames(data_set) <- c("y","x")
p_val <- lm(y ~ x, data = data_set) %>% #fitting lm
broom::tidy() %>%               # getting tidy output
dplyr::slice(-1) %>%            # removed intercept coef
dplyr::select(p.value) %>%      # selecting pvalues
as.numeric()                    # storing data in an
# append friendly way
x <- append(x, p_val)                   # storing out p-values
}
data_set <- data.frame(rnorm(1000), rnorm(1000))
colnames(data_set) <- c("y","x")
lm(y ~ x, data = data_set)
lm(y ~ x, data = data_set) %>% #fitting lm
broom::tidy()
library("dplyr")
library("broom")
lm(y ~ x, data = data_set) %>% #fitting lm
broom::tidy()
lm(y ~ x, data = data_set) %>% #fitting lm
broom::tidy() %>%               # getting tidy output
dplyr::slice(-1)
x <- vector()
for (i in 1:100){
data_set <- data.frame(rnorm(1000), rnorm(1000))
colnames(data_set) <- c("y","x")
p_val <- lm(y ~ x, data = data_set) %>% #fitting lm
broom::tidy() %>%               # getting tidy output
dplyr::slice(-1) %>%            # removed intercept coef
dplyr::select(p.value) %>%      # selecting pvalues
as.numeric()                    # storing data in an
# append friendly way
x <- append(x, p_val)                   # storing out p-values
}
hist(x,
col = "steelblue",
main = "Distribution of p-values",
# sub = "test",
xlab = "P-value",
ylab = "Count")
data_set <- data.frame(rnorm(1000), rnorm(1000))
colnames(data_set) <- c("y","x")
# lets fit our linear model
p_val <- lm(y ~ x, data = data_set) %>%
# then lets extract our 'tidy' output
broom::tidy() %>%
# then we will remove the intercept coefficient
dplyr::slice(-1) %>%
# then we will select select our p-values
dplyr::select(p.value)
data_set
rm(data_set)
data_set <- data.frame(rnorm(1000), rnorm(1000))
colnames(data_set) <- c("y","x")
# lets fit our linear model
p_val <- lm(y ~ x, data = data_set) %>%
# then lets extract our 'tidy' output
broom::tidy() %>%
# then we will remove the intercept coefficient
dplyr::slice(-1) %>%
# then we will select select our p-values
dplyr::select(p.value)
data_set
p_val
for (i in 1:100){
data_set <- data.frame(rnorm(1000), rnorm(1000))
colnames(data_set) <- c("y","x")
# lets fit our linear model
p_val <- lm(y ~ x, data = data_set) %>%
# then lets extract our 'tidy' output
broom::tidy() %>%
# then we will remove the intercept coefficient
dplyr::slice(-1) %>%
# then we will select select our p-values
dplyr::select(p.value) #%>%
# then we will
#as.numeric()
# append friendly way
x <- append(x, p_val)                   # storing out p-values
}
x
len(x)
length(x)
x <- vector()
for (i in 1:100){
data_set <- data.frame(rnorm(1000), rnorm(1000))
colnames(data_set) <- c("y","x")
# lets fit our linear model
p_val <- lm(y ~ x, data = data_set) %>%
# then lets extract our 'tidy' output
broom::tidy() %>%
# then we will remove the intercept coefficient
dplyr::slice(-1) %>%
# then we will select select our p-values
dplyr::select(p.value) #%>%
# storing our generated p-value in a list of p-values
x <- append(x, p_val)
}
hist(x,
col = "steelblue",
main = "Distribution of p-values",
# sub = "test",
xlab = "P-value",
ylab = "Count")
x <- as.numeric(x)
hist(x,
col = "steelblue",
main = "Distribution of p-values",
# sub = "test",
xlab = "P-value",
ylab = "Count")
x2 <- vector()
double_sig <- 0
hist(x2,
col = "steelblue",
main = "Distribution of p-values",
xlab = "P-values")
x2 <- vector()
double_sig <- 0
for (i in 1:1000){
# creating testing data
data_set <- data.frame(rnorm(1000),
rnorm(1000),
rnorm(1000)
)
colnames(data_set) <- c("y", "x1", "x2")
#fitting lm
p_vals <- lm(y ~ x1 + x2, data = data_set) %>%
# then obtaining tidy output
broom::tidy() %>%
# then removing intercept coef
dplyr::slice(-1) %>%
# then selecting pvalues
dplyr::select(term, p.value)
# checking stopping criteria
# IF both at least one coefficients is not significant
# then we remove the coefficient with a higher p-value
# and re-run the regression
if (sum(p_vals$p.val > 0.05) >= 1) {
var_keep <- which.min(p_vals$p.val) + 1
data_set <- data_set %>%
dplyr::select(c(1,var_keep))
p_vals <- lm(y ~ ., data = data_set) %>%
broom::tidy() %>%
dplyr::slice(-1) %>%
dplyr::select(p.value) %>%
as.numeric()
x2 <- append(x2, p_vals)
# otherwise, we will record that both coefficients were significant
} else {
double_sig <- double_sig + 1
}
}
length(x2)
length(x2)
hist(x2,
col = "steelblue",
main = "Distribution of p-values",
xlab = "P-values")
double_sig
hist(x2,
col = "steelblue",
main = "Distribution of p-values",
xlab = "P-values")
library("dplyr")
library("broom")
set.seed(123)
x <- vector()
sim1 <- 100
# lets run this simulation 10,000 times
for (i in 1:sim1){
data_set <- data.frame(rnorm(1000), rnorm(1000))
colnames(data_set) <- c("y","x")
# lets fit our linear model
p_val <- lm(y ~ x, data = data_set) %>%
# then lets extract our 'tidy' output
broom::tidy() %>%
# then we will remove the intercept coefficient
dplyr::slice(-1) %>%
# then we will select select our p-values
dplyr::select(p.value) #%>%
# storing our generated p-value in a list of p-values
x <- append(x, p_val)
}
# storing our list of p-values as a vector for easier plotting etc.
x <- as.numeric(x)
# looking at our results
hist(x,
col = "steelblue",
main = "Distribution of p-values",
# sub = "test",
xlab = "P-value",
ylab = "Count")
x2 <- vector()
double_sig <- 0
# lets simulate this situation 10000 times.
sim2_num <- 1000
for (i in 1:sim2_num){
# creating testing data
data_set <- data.frame(rnorm(1000),
rnorm(1000),
rnorm(1000)
)
colnames(data_set) <- c("y", "x1", "x2")
#fitting lm
p_vals <- lm(y ~ x1 + x2, data = data_set) %>%
# then obtaining tidy output
broom::tidy() %>%
# then removing intercept coef
dplyr::slice(-1) %>%
# then selecting pvalues
dplyr::select(term, p.value)
# checking stopping criteria
# IF both at least one coefficients is not significant
# then we remove the coefficient with a higher p-value
# and re-run the regression
if (sum(p_vals$p.val > 0.05) >= 1) {
var_keep <- which.min(p_vals$p.val) + 1
data_set <- data_set %>%
dplyr::select(c(1,var_keep))
p_vals <- lm(y ~ ., data = data_set) %>%
broom::tidy() %>%
dplyr::slice(-1) %>%
dplyr::select(p.value) %>%
as.numeric()
x2 <- append(x2, p_vals)
# otherwise, we will record that both coefficients were significant
} else {
double_sig <- double_sig + 1
}
}
hist(x2,
col = "steelblue",
main = "Distribution of p-values",
xlab = "P-values")
sum(x2 < 0.05) * sim2_num
sum(x2 < 0.05) / sim2_num
